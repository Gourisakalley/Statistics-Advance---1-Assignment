{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46b148-00fe-4325-8d9f-a5b579ed75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q - 1. Explain the properties of the F-distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4893402b-04fa-4541-b150-509cf535ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties of F-Distribution \n",
    "## 1. Range: Values range from 0 to + âˆž, meaning it only takes positive values.\n",
    "\n",
    "## 2. Skewness: It is positively skewed, but as degrees of freedom increase, it becomes closer to a normal distribution.\n",
    "\n",
    "## 3. Degrees of Freedom: Defined by two sets of degrees of freedom, d1 (numerator) and  d2(denominator).\n",
    "\n",
    "## Mean: Exists only if d2 > 2  and is given by d2 / d2 - 2.\n",
    "\n",
    "## 5. Variance: Exists only if d2 > 4 and is calculated as $$\\text{Variance} = \\frac{2 \\cdot d_2^2 \\cdot (d_1 + d_2 - 2)}{d_1 \\cdot (d_2 - 2)^2 \\cdot (d_2 - 4)}$$ .\n",
    "\n",
    "## 6. Use in Hypothesis Testing: Commonly used in ANOVA to test if variances of two populations are significantly different.\n",
    "\n",
    "\n",
    "# Summary of F-Distribution\n",
    "\n",
    "    #The F-distribution is used in statistics to compare the variances of two populations. It is positively skewed, has two degrees of freedom, and ranges from  to . Commonly applied in tests like ANOVA, it helps check if two population variances differ.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679810b9-6aa2-499f-9c3d-9b3ce596829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q - 2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a8572e-5ec2-409f-b36b-b688bc5a595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The F-distribution is mainly used in the following types of statistical tests:\n",
    "\n",
    "#1. ANOVA (Analysis of Variance): Used to compare the variances between multiple groups to see if they are significantly different. The F-distribution is appropriate because it helps in determining if the observed variances are likely due to random chance or true differences between groups.\n",
    "\n",
    "\n",
    "#2. Regression Analysis: Used to test the overall significance of a regression model by comparing the explained variance to unexplained variance. The F-distribution is suitable here as it evaluates if the model fits the data better than a model with no predictors.\n",
    "\n",
    "\n",
    "#3. Equality of Variances: Tests like the F-test are used to compare the variances of two populations. The F-distribution is appropriate  because it is designed to handle ratios of variances, helping assess if the populations have similar spread.\n",
    "\n",
    "\n",
    "#Summary of F-Distribution Usage\n",
    "\n",
    "    #The F-distribution is used in ANOVA, regression analysis, and equality of variance tests to compare variances and check model significance. It is appropriate because it handles variance ratios effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36449d12-9690-4da2-bd46-52e019ba9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q - 3. What are the key assumptions required for conducting an F-test to compare the variances of two populations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d3c460-1bb7-4c12-83e2-72cb3ff48b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The key assumptions for conducting an F-test to compare the variances of two populations are:\n",
    "\n",
    "#1. Normality: Both populations should be normally distributed.\n",
    "\n",
    "\n",
    "#2. Independence: The samples from each population must be independent of each other.\n",
    "\n",
    "\n",
    "#3. Random Sampling: Samples should be randomly selected from each population.\n",
    "\n",
    "\n",
    "#4. Ratio of Variances: The F-test assumes that the ratio of variances is meaningful, often implying the populations have equal variances under the null hypothesis.\n",
    "\n",
    "\n",
    "#Summary of F-Test Assumptions\n",
    "\n",
    "    ##For an F-test, the populations should be normally distributed, sampled independently, and selected randomly, with the assumption that their variances can be meaningfully compared.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986116e-be8c-4b07-b166-620c84134b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q - 4. What is the purpose of ANOVA, and how does it differ from a t-test? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57c5eb-f2a9-42b9-a9a9-3847cfc17323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The purpose of ANOVA (Analysis of Variance) is to test if there are significant differences among the means of three or more groups. It checks if at least one group mean differs from the others by comparing variances.\n",
    "\n",
    "#How it Differs from a t-test:\n",
    "\n",
    "#ANOVA: Compares means of three or more groups simultaneously.\n",
    "\n",
    "#t-test: Compares means of only two groups.\n",
    "\n",
    "\n",
    "#Using ANOVA instead of multiple t-tests reduces the chance of Type I error (false positives).\n",
    "\n",
    "\n",
    "#Summary of ANOVA vs. t-test\n",
    "\n",
    "    ##ANOVA tests for differences among three or more group means, while a t-test compares only two group means. ANOVA reduces the risk of Type I error compared to performing multiple t-tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089c8f26-b6be-4c81-9a27-c0a29d94b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q - 5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d3b12-749d-4bd2-b9ca-27e25b0e2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When comparing the means of three or more groups, a one-way ANOVA is used instead of multiple t-tests because:\n",
    "\n",
    "#1. Efficiency: ANOVA can compare all groups in a single test, while multiple t-tests would require multiple comparisons.\n",
    "\n",
    "\n",
    "#2. Error Control: Each t-test increases the risk of a Type I error (false positive). Using multiple t-tests increases this risk cumulatively, but one-way ANOVA controls this error by performing a single, overall test to check if any group mean is different.\n",
    "\n",
    "\n",
    "#3. Purpose: One-way ANOVA tells if at least one group mean is significantly different from others, rather than just comparing two groups at a time as t-tests do.\n",
    "\n",
    "\n",
    "\n",
    "#When to Use One-Way ANOVA:\n",
    "\n",
    "#Use it when:\n",
    "\n",
    "#There are three or more groups.\n",
    "\n",
    "#The goal is to see if any significant difference exists among them without inflating error rates.\n",
    "\n",
    "\n",
    "#Summary of Using One-Way ANOVA vs. Multiple t-tests\n",
    "\n",
    "    ##One-way ANOVA is used to compare three or more groups because it tests all groups at once, controlling Type I error better than multiple t-tests. It checks if at least one group mean differs from the others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615eef97-557a-441d-8daa-6e883d4e2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q - 6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafe64a-1a3f-4ba5-b886-f72177f96f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In ANOVA, variance is partitioned into two main components:\n",
    "\n",
    "#1. Between-Group Variance:\n",
    "\n",
    "#This measures the variability among the group means. It reflects how much the means of the different groups differ from the overall mean.\n",
    "\n",
    "#It is calculated as:\n",
    "    #\\text{Between-Group Variance} = \\frac{\\sum_{i=1}^{k} n_i (\\bar{X}_i - \\bar{X})^2}{k - 1}\n",
    "\n",
    "#2. Within-Group Variance:\n",
    "\n",
    "#This measures the variability within each group. It reflects how much the individual observations differ from their respective group means.\n",
    "\n",
    "#It is calculated as:\n",
    "    #\\text{Within-Group Variance} = \\frac{\\sum_{i=1}^{k} \\sum_{j=1}^{n_i} (X_{ij} - \\bar{X}_i)^2}{N - k}\n",
    "\n",
    "#Contribution to the F-statistic\n",
    "\n",
    "#The F-statistic is calculated by comparing the between-group variance to the within-group variance:\n",
    "    #F = \\frac{\\text{Between-Group Variance}}{\\text{Within-Group Variance}}\n",
    "\n",
    "#This partitioning allows ANOVA to assess whether observed differences among group means are due to actual differences between the groups rather than random variation within the groups.\n",
    "\n",
    "\n",
    "#Summary of Variance Partitioning in ANOVA\n",
    "\n",
    "    ##In ANOVA, variance is divided into between-group variance (reflecting differences among group means) and within-group variance (reflecting variability within each group). The F-statistic compares these variances, calculated as:\n",
    "\n",
    "#F = \\frac{\\text{Between-Group Variance}}{\\text{Within-Group Variance}}\n",
    "\n",
    "#A higher F-value indicates significant differences among group means, helping to determine if the groups differ meaningfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d6dd81-70a6-403b-8127-956a39b0f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q - 7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae0f70-e1d8-4f33-a462-c3755444d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of Classical (Frequentist) and Bayesian Approaches to ANOVA\n",
    "\n",
    "#1. Handling Uncertainty:\n",
    "\n",
    "#Frequentist: Uses p-values and confidence intervals based on long-run frequencies.\n",
    "\n",
    "#Bayesian: Uses probabilities and updates beliefs through prior and posterior distributions.\n",
    "\n",
    "\n",
    "\n",
    "#2. Parameter Estimation:\n",
    "\n",
    "#Frequentist: Considers parameters fixed; provides point estimates with standard errors.\n",
    "\n",
    "#Bayesian: Treats parameters as random; provides estimates from posterior distributions with credible intervals.\n",
    "\n",
    "\n",
    "\n",
    "#3. Hypothesis Testing:\n",
    "\n",
    "#Frequentist: Uses null hypothesis significance testing with a fixed significance level (alpha).\n",
    "\n",
    "#Bayesian: Uses Bayes factors to compare hypotheses and assess evidence.\n",
    "\n",
    "#Key Differences\n",
    "\n",
    "#Interpretation of Probability: Frequentist views probability as long-run frequency, while Bayesian views it as a degree of belief.\n",
    "\n",
    "#Use of Prior Information: Bayesian methods incorporate prior beliefs, while frequentist methods rely solely on the data at hand.\n",
    "\n",
    "#Nature of Estimates: Frequentist provides point estimates and confidence intervals; Bayesian provides distributions (credible intervals) that account for prior information and data.\n",
    "\n",
    "\n",
    "#Summary of Classical vs. Bayesian Approaches to ANOVA\n",
    "\n",
    "    ##The classical (frequentist) approach uses p-values and confidence intervals to quantify uncertainty, treats parameters as fixed, and employs null hypothesis significance testing. In contrast, the Bayesian approach incorporates prior beliefs, expresses uncertainty through probabilities, and uses Bayes factors for hypothesis testing. The key difference lies in the frequentist's focus on data alone versus the Bayesian's integration of prior information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648c827-32e2-4441-be59-b7dce5d206dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q - 8. Question: You have two sets of data representing the incomes of two different professions:\n",
    "#v Profession A: [48, 52, 55, 60, 62'\n",
    "#V Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
    "#incomes are equal. What are your conclusions based on the F-test?\n",
    "\n",
    "#Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
    "\n",
    "#Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8589441a-3872-46d1-8a82-9443df94f313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 2.0892\n",
      "P-value: 0.2465\n"
     ]
    }
   ],
   "source": [
    "#Python Code\n",
    "\n",
    "import numpy as np \n",
    "import scipy.stats as stats \n",
    "\n",
    "# Data for both professions\n",
    "profession_a = np.array([48, 52, 55, 60, 62])\n",
    "profession_b = np.array([45, 50, 55, 52, 47])\n",
    "\n",
    "# Calculate the variances\n",
    "var_a = np.var(profession_a, ddof=1)  # Sample variance\n",
    "var_b = np.var(profession_b, ddof=1)  # Sample variance\n",
    "\n",
    "# Calculate the F-statistic\n",
    "f_statistic = var_a / var_b\n",
    "\n",
    "# Calculate the p-value\n",
    "df1 = len(profession_a) - 1  # degrees of freedom for profession A\n",
    "df2 = len(profession_b) - 1  # degrees of freedom for profession B\n",
    "p_value = stats.f.sf(f_statistic, df1, df2)  # Right-tail test\n",
    "\n",
    "# Print the results\n",
    "print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0da17-b819-4630-aee9-e0f291828544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpreting Results\n",
    "\n",
    "#F-statistic: A higher value indicates a greater difference between the group variances.\n",
    "\n",
    "#P-value: If the p-value is less than the significance level (commonly 0.05), you reject the null hypothesis, concluding that the variances are significantly different.\n",
    "\n",
    "\n",
    "#Conclusion\n",
    "\n",
    "    #Run the code in your Python environment, and based on the output:\n",
    "\n",
    "#If the p-value is greater than 0.05, you can conclude that there is no significant difference in variances.\n",
    "\n",
    "#If the p-value is less than or equal to 0.05, you can conclude that the variances of the two professions' incomes are significantly different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b1707-5083-4cae-9f13-025c34ff41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q - 9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in\n",
    "#average heights between three different regions with the following data1\n",
    "#V Region A: [160, 162, 165, 158, 164'\n",
    "#V Region B: [172, 175, 170, 168, 174'\n",
    "#V Region C: [180, 182, 179, 185, 183'\n",
    "#V Task: Write Python code to perform the one-way ANOVA and interpret the results\f",
    "\n",
    "#V Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf923452-7584-48c3-bbc5-69d299abcd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 67.8733\n",
      "P-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "\n",
    "#Region A: [160, 162, 165, 158, 164]\n",
    "\n",
    "#Region B: [172, 175, 170, 168, 174]\n",
    "\n",
    "#Region C: [180, 182, 179, 185, 183]\n",
    "\n",
    "#Python Code\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "# Data for the three regions\n",
    "region_a = np.array([160, 162, 165, 158, 164])\n",
    "region_b = np.array([172, 175, 170, 168, 174])\n",
    "region_c = np.array([180, 182, 179, 185, 183])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(region_a, region_b, region_c)\n",
    "\n",
    "# Print the results\n",
    "print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf15bf7-a782-445c-ab1a-16b9c4b1db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F-statistic: This value indicates the ratio of the variance between the groups to the variance within the groups. A higher F-statistic suggests that the group means are more different than would be expected by chance.\n",
    "#P-value: This value helps determine the statistical significance of the results. Typically, if the p-value is less than the significance level (commonly set at 0.05), you reject the null hypothesis, which states that there are no differences in average heights among the regions. If the p-value is greater than 0.05, you fail to reject the null hypothesis, suggesting no significant differences.\n",
    "\n",
    "\n",
    "#Conclusion\n",
    "\n",
    "    #Run the code in your Python environment, and based on the output:\n",
    "\n",
    "#If the p-value is less than or equal to 0.05, you can conclude that there are significant differences in average heights between at least one pair of regions.\n",
    "\n",
    "#If the p-value is greater than 0.05, you can conclude that there are no significant differences in average heights among the three regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f45d0-1eb2-4d5a-a792-0b0efb65d44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
